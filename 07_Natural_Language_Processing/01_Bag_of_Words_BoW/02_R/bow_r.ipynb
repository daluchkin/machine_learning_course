{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6198454c-999a-4b30-82d6-7424551106a0",
   "metadata": {},
   "source": [
    "**Natural Language Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfcfc40-cdd8-4142-a150-c42cee9472e6",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b8670-e70b-4d05-8e16-d9de1805e2bd",
   "metadata": {},
   "source": [
    "A typical Bag of Words (BoW) vector represents a text document as a numerical array, where each element corresponds to the frequency (or presence) of a specific word in the vocabulary.\n",
    "\n",
    "A structured representation of a BoW vector can look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d39fd-93d3-44d8-a52a-dc991e8fb32a",
   "metadata": {},
   "source": [
    "[**SoS**, **EoS**, ...frequency of words..., **frequency of special words**]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64161a7e-1857-498c-8e1f-fcb9dcb4c850",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "+ **SoS** (Start of Sentence Token) – Optional. Can be used to indicate the beginning of a sentence.\n",
    "+ **EoS** (End of Sentence Token) – Optional. Marks the end of a sentence.\n",
    "+ **frequency of words** – The main part of the vector, representing the frequency or presence of each word in the vocabulary.\n",
    "+ **frequency of special words** – Can include punctuation, stop words, named entities, or special tokens (e.g., <UNK> for unknown words)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef192d9f-5a5b-4930-afb9-f48ac794d726",
   "metadata": {},
   "source": [
    "## Step-by-step\n",
    "\n",
    "### Step 1. Collect and Prepare Text Data\n",
    "- Gather a set of text documents (e.g., emails, reviews, or news articles).  \n",
    "- Label the data if needed (e.g., spam vs. not spam).  \n",
    "\n",
    "### Step 2. Clean and Preprocess the Text\n",
    "- Convert text to lowercase.  \n",
    "- Remove punctuation, numbers, and special characters.  \n",
    "- Remove stop words (common words like \"the\", \"and\", \"is\" that don’t add much meaning).  \n",
    "- Tokenize the text (split sentences into words).  \n",
    "\n",
    "### Step 3. Convert Sentences into Vectors using Bag of Words\n",
    "- Create a vocabulary (a list of all unique words in the dataset).  \n",
    "- Count how many times each word appears in each document.  \n",
    "- Represent each document as a vector of word counts.  \n",
    "\n",
    "### Step 4. Split Data into Training and Testing Sets\n",
    "- Divide the dataset into a training set (to teach the model) and a test set (to check its accuracy).  \n",
    "\n",
    "### Step 5. Train a Machine Learning Model\n",
    "- Use a classification algorithm (e.g., Naive Bayes, Logistic Regression, or SVM) or a neural network.\n",
    "- Feed the BoW vectors into the model so it learns patterns in the data.  \n",
    "\n",
    "### Step 6. Test and Evaluate the Model\n",
    "- Use the test set to check how well the model can predict labels for new text.  \n",
    "- Measure accuracy and other performance metrics.  \n",
    "\n",
    "### Step 7. Make Predictions on New Text\n",
    "- Convert new sentences into BoW vectors.  \n",
    "- Feed them into the trained model to get predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71011155-1565-4a35-bb0c-2a70cfc2060a",
   "metadata": {},
   "source": [
    "## Libraries Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16e860a-8447-46f6-926d-6e1667d216d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages('tm')\n",
    "# install.packages('SnowballC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c566fa34-d8ac-4fea-a599-ca5c65630a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tm)\n",
    "library(SnowballC)\n",
    "library(rpart)\n",
    "library(caret)\n",
    "library(ggplot2)\n",
    "library(MLmetrics)\n",
    "library(class)\n",
    "library(e1071)\n",
    "library(randomForest)\n",
    "library(pROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16241d5c-c1bd-4fd8-b52e-0695138f5a61",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0ad8e41-2aa0-4f0f-9567-eecb648c129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m1000\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m2\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m───────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \"\\t\"\n",
      "\u001b[31mchr\u001b[39m (1): Review\n",
      "\u001b[32mdbl\u001b[39m (1): Liked\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Review</th><th scope=col>Liked</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Wow... Loved this place.                                                               </td><td>1</td></tr>\n",
       "\t<tr><td>Crust is not good.                                                                     </td><td>0</td></tr>\n",
       "\t<tr><td>Not tasty and the texture was just nasty.                                              </td><td>0</td></tr>\n",
       "\t<tr><td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td><td>1</td></tr>\n",
       "\t<tr><td>The selection on the menu was great and so were the prices.                            </td><td>1</td></tr>\n",
       "\t<tr><td>Now I am getting angry and I want my damn pho.                                         </td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " Review & Liked\\\\\n",
       " <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t Wow... Loved this place.                                                                & 1\\\\\n",
       "\t Crust is not good.                                                                      & 0\\\\\n",
       "\t Not tasty and the texture was just nasty.                                               & 0\\\\\n",
       "\t Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. & 1\\\\\n",
       "\t The selection on the menu was great and so were the prices.                             & 1\\\\\n",
       "\t Now I am getting angry and I want my damn pho.                                          & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 2\n",
       "\n",
       "| Review &lt;chr&gt; | Liked &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| Wow... Loved this place.                                                                | 1 |\n",
       "| Crust is not good.                                                                      | 0 |\n",
       "| Not tasty and the texture was just nasty.                                               | 0 |\n",
       "| Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. | 1 |\n",
       "| The selection on the menu was great and so were the prices.                             | 1 |\n",
       "| Now I am getting angry and I want my damn pho.                                          | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Review                                                                                 \n",
       "1 Wow... Loved this place.                                                               \n",
       "2 Crust is not good.                                                                     \n",
       "3 Not tasty and the texture was just nasty.                                              \n",
       "4 Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
       "5 The selection on the menu was great and so were the prices.                            \n",
       "6 Now I am getting angry and I want my damn pho.                                         \n",
       "  Liked\n",
       "1 1    \n",
       "2 0    \n",
       "3 0    \n",
       "4 1    \n",
       "5 1    \n",
       "6 0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1.\n",
    "data = read_delim('../00_data/Restaurant_Reviews.tsv')\n",
    "\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185f16e9-5ced-4397-911a-02acbeb0e89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Review</th><th scope=col>Liked</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>I can't tell you how disappointed I was.                                                                                              </td><td>0</td></tr>\n",
       "\t<tr><td>I think food should have flavor and texture and both were lacking.                                                                    </td><td>0</td></tr>\n",
       "\t<tr><td>Appetite instantly gone.                                                                                                              </td><td>0</td></tr>\n",
       "\t<tr><td>Overall I was not impressed and would not go back.                                                                                    </td><td>0</td></tr>\n",
       "\t<tr><td>The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.                                           </td><td>0</td></tr>\n",
       "\t<tr><td>Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check.</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " Review & Liked\\\\\n",
       " <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t I can't tell you how disappointed I was.                                                                                               & 0\\\\\n",
       "\t I think food should have flavor and texture and both were lacking.                                                                     & 0\\\\\n",
       "\t Appetite instantly gone.                                                                                                               & 0\\\\\n",
       "\t Overall I was not impressed and would not go back.                                                                                     & 0\\\\\n",
       "\t The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.                                            & 0\\\\\n",
       "\t Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check. & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 2\n",
       "\n",
       "| Review &lt;chr&gt; | Liked &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| I can't tell you how disappointed I was.                                                                                               | 0 |\n",
       "| I think food should have flavor and texture and both were lacking.                                                                     | 0 |\n",
       "| Appetite instantly gone.                                                                                                               | 0 |\n",
       "| Overall I was not impressed and would not go back.                                                                                     | 0 |\n",
       "| The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.                                            | 0 |\n",
       "| Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check. | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Review                                                                                                                                \n",
       "1 I can't tell you how disappointed I was.                                                                                              \n",
       "2 I think food should have flavor and texture and both were lacking.                                                                    \n",
       "3 Appetite instantly gone.                                                                                                              \n",
       "4 Overall I was not impressed and would not go back.                                                                                    \n",
       "5 The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.                                           \n",
       "6 Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check.\n",
       "  Liked\n",
       "1 0    \n",
       "2 0    \n",
       "3 0    \n",
       "4 0    \n",
       "5 0    \n",
       "6 0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22af37fb-610a-4ea7-933a-56f07c77c5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1000</li><li>2</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 2\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 2\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000    2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50fa78c-e3af-4117-8694-427a80b19b9b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9f7ce3-e0f3-4267-a940-0aa81b9a39c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Wow... Loved this place.'"
      ],
      "text/latex": [
       "'Wow... Loved this place.'"
      ],
      "text/markdown": [
       "'Wow... Loved this place.'"
      ],
      "text/plain": [
       "[1] \"Wow... Loved this place.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2.\n",
    "corpus <- VCorpus(VectorSource(data$Review))\n",
    "as.character(corpus[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a93b8a0-efd5-46d5-b512-a4fedaa6aad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'wow... loved this place.'"
      ],
      "text/latex": [
       "'wow... loved this place.'"
      ],
      "text/markdown": [
       "'wow... loved this place.'"
      ],
      "text/plain": [
       "[1] \"wow... loved this place.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make lowercases\n",
    "corpus <- tm_map(corpus, content_transformer(tolower))\n",
    "as.character(corpus[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860b3767-2f4a-4cc1-a97c-065610634898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"for 40 bucks a head, i really expect better food.\"\n",
      "[1] \"for  bucks a head, i really expect better food.\"\n"
     ]
    }
   ],
   "source": [
    "# remove numbers\n",
    "print(as.character(corpus[[841]]))\n",
    "corpus <- tm_map(corpus, removeNumbers)\n",
    "print(as.character(corpus[[841]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8cec40-7198-45cb-8072-4bb57f6b2639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"for  bucks a head, i really expect better food.\"\n",
      "[1] \"for  bucks a head i really expect better food\"\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation\n",
    "print(as.character(corpus[[841]]))\n",
    "corpus <- tm_map(corpus, removePunctuation)\n",
    "print(as.character(corpus[[841]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d865889-a6d9-4b03-9831-1c0d9d79b350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'wow loved  place'</span>"
      ],
      "text/latex": [
       "'wow loved  place'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'wow loved  place'</span>"
      ],
      "text/plain": [
       "[1] \"wow loved  place\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "corpus <- tm_map(corpus, removeWords, stopwords())\n",
    "as.character(corpus[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1199b810-f9a9-4322-9d41-5335ad03f22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'wow love place'"
      ],
      "text/latex": [
       "'wow love place'"
      ],
      "text/markdown": [
       "'wow love place'"
      ],
      "text/plain": [
       "[1] \"wow love place\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stemming\n",
    "corpus <- tm_map(corpus, stemDocument)\n",
    "as.character(corpus[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0322bba9-9c4a-4fee-bf99-f545088bac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"buck head realli expect better food\"\n"
     ]
    }
   ],
   "source": [
    "# extra spaces\n",
    "corpus <- tm_map(corpus, stripWhitespace)\n",
    "print(as.character(corpus[[841]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b92d5-f406-432f-93af-faacabf82fc6",
   "metadata": {},
   "source": [
    "## Create Bag of Words model (Create Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1693051c-d24e-481b-aaf8-038ec0af05cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<DocumentTermMatrix (documents: 1000, terms: 1577)>>\n",
       "Non-/sparse entries: 5435/1571565\n",
       "Sparsity           : 100%\n",
       "Maximal term length: 32\n",
       "Weighting          : term frequency (tf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3.\n",
    "dtm <- DocumentTermMatrix(corpus) \n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b127c41-3df3-43f7-9e19-fc442d9f2195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<DocumentTermMatrix (documents: 1000, terms: 691)>>\n",
       "Non-/sparse entries: 4549/686451\n",
       "Sparsity           : 99%\n",
       "Maximal term length: 12\n",
       "Weighting          : term frequency (tf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# keep 99% of the most frequent words\n",
    "dtm <- removeSparseTerms(dtm, 0.999)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd0aaa3-dccb-4f4e-9b47-bfead9e3ad84",
   "metadata": {},
   "source": [
    "## Split the data into training anf test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701e8fef-d9dc-4077-b709-929299d3347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.\n",
    "data_df <- as.data.frame(as.matrix(dtm)) # convert to data frame\n",
    "data_df$Liked <- factor(data$Liked, levels=c(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f25dacd-4184-436a-9d38-07236dbd81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "set.seed(42)\n",
    "\n",
    "train_data <- data_df |> slice_sample(prop = 0.8)\n",
    "test_data <- data_df |> anti_join(train_data, by=colnames(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8de8e-05a8-4952-874f-3889fc1363c2",
   "metadata": {},
   "source": [
    "## Train a machine learning model on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fcc9ac-10b1-4a14-bf43-427b2a5b2d16",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68cc3946-671a-4722-a1ed-19ffa675ce9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " randomForest(formula = Liked ~ ., data = train_data, ntree = 100) \n",
       "               Type of random forest: classification\n",
       "                     Number of trees: 100\n",
       "No. of variables tried at each split: 26\n",
       "\n",
       "        OOB estimate of  error rate: 25.37%\n",
       "Confusion matrix:\n",
       "    0   1 class.error\n",
       "0 317  83      0.2075\n",
       "1 120 280      0.3000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5.\n",
    "\n",
    "# names `break` and `next` are reserved in randomForest and can cause issues\n",
    "colnames(train_data)[colnames(train_data) == \"break\"] <- \"break_1\"\n",
    "colnames(train_data)[colnames(train_data) == \"next\"] <- \"next_1\"\n",
    "colnames(test_data)[colnames(test_data) == \"break\"] <- \"break_1\"\n",
    "colnames(test_data)[colnames(test_data) == \"next\"] <- \"next_1\"\n",
    "\n",
    "fit <- randomForest(Liked ~ .,\n",
    "            data = train_data, \n",
    "            ntree = 100)\n",
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b4c45-bd9a-4994-9c38-5b1041e4cbae",
   "metadata": {},
   "source": [
    "## Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "608ff52c-3b4a-4baa-95ba-aca7c2cd3fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>5</dt><dd>1</dd><dt>6</dt><dd>0</dd><dt>15</dt><dd>0</dd><dt>29</dt><dd>0</dd><dt>36</dt><dd>0</dd><dt>38</dt><dd>1</dd></dl>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'0'</li><li>'1'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[5] 1\n",
       "\\item[6] 0\n",
       "\\item[15] 0\n",
       "\\item[29] 0\n",
       "\\item[36] 0\n",
       "\\item[38] 1\n",
       "\\end{description*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item '0'\n",
       "\\item '1'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "5\n",
       ":   16\n",
       ":   015\n",
       ":   029\n",
       ":   036\n",
       ":   038\n",
       ":   1\n",
       "\n",
       "\n",
       "**Levels**: 1. '0'\n",
       "2. '1'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " 5  6 15 29 36 38 \n",
       " 1  0  0  0  0  1 \n",
       "Levels: 0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6.\n",
    "#test_data <- test_data[, !names(test_data) %in% c(\"break\", \"next\")]\n",
    "y_pred <- predict(fit, newdata=test_data)\n",
    "head(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a4587-bfe6-4aa7-854c-362db5601a7f",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88984a8f-1648-4c16-b5e4-01d8d7d9cad5",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "899f74be-0617-4c9b-b8d3-eaebb927c95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y_pred\n",
      "     0  1\n",
      "  0 77 17\n",
      "  1 27 70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cm <- table(test_data$Liked, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ac6458-9e13-42b7-8367-15001ec6923b",
   "metadata": {},
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18dc591b-1ba4-4d92-b546-62d45fb934a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy on test set: 76.96%\"\n"
     ]
    }
   ],
   "source": [
    "accuracy <- mean(test_data$Liked == y_pred)\n",
    "print(paste0('Accuracy on test set: ', round(accuracy*100, 2), \"%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b726f54-331d-447c-9b25-385e5999e17b",
   "metadata": {},
   "source": [
    "## Predict a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a06fc4bd-164a-4429-9c29-4cfd9a5bc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da65ef26-b33d-4366-8c4c-4677d512364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_classifier <- function(classifier, model_terms, new_review){    \n",
    "    # preprocessing a new data\n",
    "    new_corpus <- VCorpus(VectorSource(new_review))\n",
    "    new_corpus <- tm_map(new_corpus, content_transformer(tolower)) # lowercases\n",
    "    new_corpus <- tm_map(new_corpus, removeNumbers)                # remove numbers\n",
    "    new_corpus <- tm_map(new_corpus, removePunctuation)            # remove punctuations\n",
    "    new_corpus <- tm_map(new_corpus, removeWords, stopwords(\"en\")) # remove stopwords\n",
    "    new_corpus <- tm_map(new_corpus, stemDocument)                 # stemming\n",
    "    new_corpus <- tm_map(new_corpus, stripWhitespace)              # remove extra whitespaces\n",
    "    \n",
    "    new_dtm <- DocumentTermMatrix(new_corpus)\n",
    "    \n",
    "    new_dtm <- as.matrix(new_dtm)\n",
    "    new_dtm <- new_dtm[, colnames(new_dtm) %in% model_terms, drop = FALSE]\n",
    "    \n",
    "    # add missing terms with zeros\n",
    "    missing_terms <- setdiff(model_terms, colnames(new_dtm))\n",
    "    for (term in missing_terms) {\n",
    "      new_dtm <- cbind(new_dtm, matrix(0, nrow = nrow(new_dtm), ncol = 1, dimnames = list(NULL, term)))\n",
    "    }\n",
    "    \n",
    "    new_dtm <- new_dtm[, model_terms, drop = FALSE]\n",
    "    # rename reserved words\n",
    "    colnames(new_dtm)[colnames(new_dtm) == \"break\"] <- \"break_1\"\n",
    "    colnames(new_dtm)[colnames(new_dtm) == \"next\"] <- \"next_1\"\n",
    "    \n",
    "    prediction <- predict(fit, new_dtm)\n",
    "    \n",
    "    return(prediction)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81feadb0-d1ed-49f9-9a5e-7ca24036d617",
   "metadata": {},
   "source": [
    "+ **Positive Review:**\n",
    "  > The food was exceptional, with fresh ingredients and bold flavors. Friendly staff, cozy atmosphere, and quick service made it a delightful experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72da3c37-51de-40ea-aaa4-06cb02e59817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 1\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'0'</li><li>'1'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\textbf{1:} 1\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item '0'\n",
       "\\item '1'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "**1:** 1\n",
       "**Levels**: 1. '0'\n",
       "2. '1'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "1 \n",
       "1 \n",
       "Levels: 0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_review <- c('The food was exceptional, with fresh ingredients and bold flavors. Friendly staff, cozy atmosphere, and quick service made it a delightful experience.')\n",
    "pos_neg_classifier(fit, Terms(dtm), new_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa6901-db28-4c50-b1ca-ce7d19dd1c60",
   "metadata": {},
   "source": [
    "+ **Negative Review:**\n",
    "  > Disappointing experience—slow service, overpriced dishes, and bland flavors. The ambiance was noisy, and the staff seemed inattentive. Not worth the visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d0faf19-ed47-461f-8ef7-bbb9161b246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 0\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'0'</li><li>'1'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\textbf{1:} 0\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item '0'\n",
       "\\item '1'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "**1:** 0\n",
       "**Levels**: 1. '0'\n",
       "2. '1'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "1 \n",
       "0 \n",
       "Levels: 0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_review <- c('Disappointing experience—slow service, overpriced dishes, and bland flavors. The ambiance was noisy, and the staff seemed inattentive. Not worth the visit.')\n",
    "pos_neg_classifier(fit, Terms(dtm), new_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521a04f-5256-4799-8c0a-a57242ca563b",
   "metadata": {},
   "source": [
    "## The best model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6abdce5-e48c-4799-9b01-bdcdc8ee7609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Running KNN...\"\n",
      "$name\n",
      "[1] \"KNN\"\n",
      "\n",
      "$confusion_matrix\n",
      "   y_pred\n",
      "     0  1\n",
      "  0 82 12\n",
      "  1 55 42\n",
      "\n",
      "$scores\n",
      "$scores$f1\n",
      "[1] 0.5562914\n",
      "\n",
      "$scores$`roc-auc`\n",
      "Area under the curve: 0.7085\n",
      "\n",
      "$scores$accuracy\n",
      "[1] 0.6492147\n",
      "\n",
      "\n",
      "[1] \"Running SVM...\"\n",
      "$name\n",
      "[1] \"SVM\"\n",
      "\n",
      "$confusion_matrix\n",
      "   y_pred\n",
      "     0  1\n",
      "  0 76 18\n",
      "  1 16 81\n",
      "\n",
      "$scores\n",
      "$scores$f1\n",
      "[1] 0.8265306\n",
      "\n",
      "$scores$`roc-auc`\n",
      "Area under the curve: 0.863\n",
      "\n",
      "$scores$accuracy\n",
      "[1] 0.8219895\n",
      "\n",
      "\n",
      "[1] \"Running Naive Bayes...\"\n",
      "$name\n",
      "[1] \"Naive Bayes\"\n",
      "\n",
      "$confusion_matrix\n",
      "   y_pred\n",
      "     0  1\n",
      "  0 19 75\n",
      "  1 26 71\n",
      "\n",
      "$scores\n",
      "$scores$f1\n",
      "[1] 0.5843621\n",
      "\n",
      "$scores$`roc-auc`\n",
      "Area under the curve: 0.4696\n",
      "\n",
      "$scores$accuracy\n",
      "[1] 0.4712042\n",
      "\n",
      "\n",
      "[1] \"Running Decision Tree...\"\n",
      "$name\n",
      "[1] \"Decision Tree\"\n",
      "\n",
      "$confusion_matrix\n",
      "   y_pred\n",
      "     0  1\n",
      "  0 85  9\n",
      "  1 38 59\n",
      "\n",
      "$scores\n",
      "$scores$f1\n",
      "[1] 0.7151515\n",
      "\n",
      "$scores$`roc-auc`\n",
      "Area under the curve: 0.7739\n",
      "\n",
      "$scores$accuracy\n",
      "[1] 0.7539267\n",
      "\n",
      "\n",
      "[1] \"Running Random Forest...\"\n",
      "$name\n",
      "[1] \"Random Forest\"\n",
      "\n",
      "$confusion_matrix\n",
      "   y_pred\n",
      "     0  1\n",
      "  0 77 17\n",
      "  1 26 71\n",
      "\n",
      "$scores\n",
      "$scores$f1\n",
      "[1] 0.7675676\n",
      "\n",
      "$scores$`roc-auc`\n",
      "Area under the curve: 0.8688\n",
      "\n",
      "$scores$accuracy\n",
      "[1] 0.7748691\n",
      "\n",
      "\n",
      "[1] \"-------------------------------------------\"\n",
      "[1] \"The best models:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$SVM\n",
       "$SVM$name\n",
       "[1] \"SVM\"\n",
       "\n",
       "$SVM$confusion_matrix\n",
       "   y_pred\n",
       "     0  1\n",
       "  0 76 18\n",
       "  1 16 81\n",
       "\n",
       "$SVM$scores\n",
       "$SVM$scores$f1\n",
       "[1] 0.8265306\n",
       "\n",
       "$SVM$scores$`roc-auc`\n",
       "Area under the curve: 0.863\n",
       "\n",
       "$SVM$scores$accuracy\n",
       "[1] 0.8219895\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_seed <- 42\n",
    "\n",
    "# get scores to choose the best model\n",
    "scores <- function(y_pred, y_prob){\n",
    "    roc_curve <- roc(test_data$Liked, y_prob, levels = c(0, 1), direction = \"<\")\n",
    "    auc_value <- auc(roc_curve)\n",
    "    accuracy <- mean(test_data$Liked == y_pred)\n",
    "    list('f1' = F1_Score(y_pred, test_data$Liked, positive = \"1\"),\n",
    "         'roc-auc' = auc_value,\n",
    "         'accuracy' = accuracy)\n",
    "}\n",
    "\n",
    "# convert probabilities to classes\n",
    "prob_to_class <- function(y_prob){\n",
    "    ifelse(y_prob > 0.5, 1, 0)\n",
    "}\n",
    "\n",
    "# get confusion matrix\n",
    "conf_mat <- function(y_pred){\n",
    "    table(test_data$Liked, y_pred)\n",
    "}\n",
    "\n",
    "# models configurations\n",
    "models_config <- list(\n",
    "  # 1. KNN\n",
    "  'KNN' = list(\n",
    "      name = 'KNN',\n",
    "      train_test = function(){\n",
    "          # fit the model on the train set and get probabilities predicted on test set\n",
    "          y_pred <- knn(train = train_data[, -ncol(test_data)],\n",
    "                        test = test_data[, -ncol(test_data)],\n",
    "                        cl = train_data$Liked, # classes from training set\n",
    "                        k = 5,\n",
    "                        prob = TRUE) # get probabilities\n",
    "\n",
    "          winning_class_probs <- attr(y_pred, \"prob\")\n",
    "          # Adjust probabilities for the positive class - 1\n",
    "          positive_probs <- ifelse(y_pred == 1, winning_class_probs, 1 - winning_class_probs)\n",
    "          \n",
    "          return(positive_probs)\n",
    "    },\n",
    "    evaluate = conf_mat,\n",
    "    scores = scores\n",
    "  ),\n",
    "  # 2. SVM\n",
    "  'SVM' = list(\n",
    "      name = 'SVM',\n",
    "      train_test = function(){\n",
    "          kernels <- list(linear = list(kernel = 'linear',\n",
    "                                        params = list(cost = c(0.1, 1, 10, 100))),\n",
    "                          redial = list(kernel = 'radial',\n",
    "                                        params = list(cost = c(0.1, 1, 10, 100), \n",
    "                                                      gamma = c(1, 0.1, 0.01))),\n",
    "                          poly = list(kernel = 'poly',\n",
    "                                      params = list(cost = c(0.1, 1, 10, 100), \n",
    "                                                    gamma = c(1, 0.1, 0.01),\n",
    "                                                    degree = 2:4))\n",
    "                         )\n",
    "          # tune params and select the best SVM kernel\n",
    "          best_models <- lapply(kernels, function(x){\n",
    "              set.seed(random_seed)\n",
    "              tuned <- tune('svm',\n",
    "                            Liked ~ .,\n",
    "                            data = train_data,\n",
    "                            kernel = x$kernel,\n",
    "                            ranges = x$params,\n",
    "                            tunecontrol = tune.control(cross = 10),\n",
    "                            probability = TRUE,\n",
    "                            scale = FALSE\n",
    "                           )\n",
    "            \n",
    "              best_model <- tuned$best.model\n",
    "              y_pred <- predict(best_model, newdata = test_data)\n",
    "              f1 <- F1_Score(y_pred, test_data$Liked, positive = \"1\")\n",
    "              list(kernel = x$kernel,\n",
    "                   best.params = tuned$best.parameters,\n",
    "                   best.f1=f1,\n",
    "                   best.model=best_model)\n",
    "          })\n",
    "          # select best SVM\n",
    "          best_model <- best_models[[which.max(sapply(best_models, function(x) x$best.f1))]]\n",
    "          # predict probabilities on test set\n",
    "          y_pred <- predict(best_model$best.model, newdata = test_data, probability = TRUE)\n",
    "          probs <- attr(y_pred, 'probabilities')\n",
    "                                                      \n",
    "          return(probs[,2])\n",
    "      },\n",
    "      evaluate = conf_mat,\n",
    "      scores = scores\n",
    "  ),\n",
    "  # 3. Naive Bayes\n",
    "  'Naive Bayes' = list(\n",
    "      name = 'Naive Bayes',\n",
    "      train_test = function(){\n",
    "          # fit the model on training set\n",
    "          fit <- naiveBayes(Liked ~ ., data = train_data)\n",
    "          # predict probabilities on teset set\n",
    "          y_pred <- predict(fit, newdata = test_data[-ncol(test_data)], type = 'raw')\n",
    "          \n",
    "          return(y_pred[, 2])\n",
    "      },\n",
    "      evaluate = conf_mat,\n",
    "      scores = scores\n",
    "  ),\n",
    "  # 4. Decision Tree\n",
    "  'Decision Tree' = list(\n",
    "      name = 'Decision Tree',\n",
    "      train_test = function(){\n",
    "          set.seed(random_seed)\n",
    "          # fit the model on training set\n",
    "          fit <- rpart(Liked ~ ., data = train_data)\n",
    "          # predict probabilities on teset set\n",
    "          y_pred <- predict(fit, newdata = test_data[-ncol(test_data)], type = 'prob')\n",
    "          \n",
    "          return(y_pred[, 2])\n",
    "      },\n",
    "      evaluate = conf_mat,\n",
    "      scores = scores\n",
    "  ),\n",
    "                                               \n",
    "  # 5. Random Forest\n",
    "  'Random Forest' = list(\n",
    "      name = 'Random Forest',\n",
    "      train_test = function(){\n",
    "          set.seed(random_seed)\n",
    "          # fit the model on training set\n",
    "          fit <- randomForest(Liked ~ .,\n",
    "                              data = train_data,\n",
    "                              ntree = 100)        \n",
    "          # predict probabilities on teset set\n",
    "          y_pred <- predict(fit, newdata = test_data, type = 'prob')\n",
    "          \n",
    "          return(y_pred[, 2])\n",
    "      },\n",
    "      evaluate = conf_mat,\n",
    "      scores = scores\n",
    "  )\n",
    ")\n",
    "\n",
    "# run experiment\n",
    "best_models <- lapply(models_config, function(x){\n",
    "    print(paste0('Running ', x[['name']], '...'))\n",
    "    # train\n",
    "    prob_pred <- x[['train_test']]()\n",
    "    #print('Model trained!')\n",
    "    y_pred <- prob_to_class(prob_pred)\n",
    "    #print('Evaluating...')\n",
    "    cm <- x[['evaluate']](y_pred)\n",
    "    # score\n",
    "    #print('Scoring...')\n",
    "    scores <- x[['scores']](y_pred, prob_pred)\n",
    "    print(list(\n",
    "        name = x[['name']],\n",
    "        confusion_matrix = cm,\n",
    "        scores = scores\n",
    "    ))\n",
    "    list(\n",
    "        name = x[['name']],\n",
    "        confusion_matrix = cm,\n",
    "        scores = scores\n",
    "    )\n",
    "})\n",
    "\n",
    "# Best model selection\n",
    "max_val <- max(sapply(best_models, function(x) x$scores$f1))\n",
    "best_of_the_best <- best_models[which(sapply(best_models, function(x) x$scores$f1) == max_val, arr.ind = TRUE)]\n",
    "\n",
    "print('-------------------------------------------')\n",
    "print('The best models:')\n",
    "\n",
    "best_of_the_best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
