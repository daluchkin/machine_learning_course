# Principal Component Analysis (PCA)

This section of the repository is dedicated to **Principal Component Analysis (PCA)** as a dimensionality reduction technique and is part of the course **Machine Learning A-Z: AI, Python & R** hosted on Udemy. You can find more information about the course [here](https://www.udemy.com/course/machinelearning/).  

## **Section Description**  

This topic presents the practical application of **Principal Component Analysis (PCA)**, structured step-by-step to optimize machine learning models by reducing dimensionality while retaining key information. **PCA** is an unsupervised learning technique that transforms correlated features into a new set of uncorrelated principal components. It is widely used in pattern recognition, image compression, and feature extraction to improve model performance and visualization. By identifying the most important axes of variation in the data, **PCA** helps remove redundancy, speed up computations, and enhance model generalization.  

## **Notebooks/Code**  

+ [Python >>](./01_Python/PCA_py.ipynb)  
+ [R >>](./02_R/PCA_r.ipynb)  

## **Tools & Libraries**  

+ **Python**: `numpy`, `matplotlib`, `pandas`, `sklearn`
+ **R**: `tidyverse`, `ggplot2`, `e1071`, `caret`

---

Feel free to suggest any improvements, leave feedback, or contact me via:
- [Email](mailto:daluchki@gmail.com)
- [GitHub](https://github.com/daluchkin)
- [LinkedIn](https://www.linkedin.com/in/dmitry-luchkin/)

Thank you for visiting my portfolio!

